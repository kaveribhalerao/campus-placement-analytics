{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6RbhwqeCfnz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,  roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn import tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9w90gd9rdQ3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpbeR167CqyI"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/Placement_Data_Full_Class.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubxC69s2CrSJ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R76ywxxbC3qg"
      },
      "outputs": [],
      "source": [
        "  df.select_dtypes(include='object').nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txCDr9ilDrjn"
      },
      "outputs": [],
      "source": [
        "check_missing = df.isnull().sum() * 100 / df.shape[0]\n",
        "check_missing[check_missing > 0].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYubUrMnKUXB"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMMDATR1KlCJ"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['status'], axis=1)\n",
        "y = df['status']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWoz0UTMKpXM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.bar(df['status'].value_counts().index, df['status'].value_counts())\n",
        "plt.xlabel('Status')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Target Variable')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opDpeyv_Ktcl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.hist(df['ssc_p'], bins=10)\n",
        "plt.xlabel('SSC Percentage')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of SSC Percentage')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC83y977uelu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pqkbUQKsgJm"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['sl_no', 'salary'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoiXiPxfr_Oi"
      },
      "outputs": [],
      "source": [
        "df['gender'] = df['gender'].map({'M': 0, 'F': 1})\n",
        "df['ssc_b'] = df['ssc_b'].map({'Central': 0, 'Others': 1})\n",
        "df['hsc_b'] = df['hsc_b'].map({'Central': 0, 'Others': 1})\n",
        "df['hsc_s'] = df['hsc_s'].map({'Commerce': 0, 'Science': 1, 'Arts': 2})\n",
        "df['degree_t'] = df['degree_t'].map({'Sci&Tech': 0, 'Comm&Mgmt': 1, 'Others': 2})\n",
        "df['workex'] = df['workex'].map({'No': 0, 'Yes': 1})\n",
        "df['specialisation'] = df['specialisation'].map({'Mkt&HR': 0, 'Mkt&Fin': 1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4T4upLsKxnZ"
      },
      "outputs": [],
      "source": [
        "X = df.drop('status', axis=1)\n",
        "y = df['status'].map({'Not Placed': 0, 'Placed': 1})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg_model = LogisticRegression(solver='lbfgs', max_iter=4000)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F6YChVCu6Xu"
      },
      "outputs": [],
      "source": [
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using logistic regression\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the logistic regression model\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print('Logistic Regression Accuracy:', accuracy_logreg)\n",
        "print('Logistic Regression Classification Report:')\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "print('Logistic Regression Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hQyaU3hwSzJ"
      },
      "outputs": [],
      "source": [
        "logreg_conf_mat = confusion_matrix(y_test, y_pred_logreg)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(logreg_conf_mat, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Logistic Regression Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZdxISn23BfJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision = precision_score(y_test, y_pred_logreg)\n",
        "recall = recall_score(y_test, y_pred_logreg)\n",
        "f1 = f1_score(y_test, y_pred_logreg)\n",
        "\n",
        "plt.bar(['Precision', 'Recall', 'F1 Score'], [precision, recall, f1])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Logistic Regression Performance Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2rDVURWvEmS"
      },
      "outputs": [],
      "source": [
        "#Create a KNeighborsClassifier model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the KNeighborsClassifier model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using KNeighborsClassifier\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the KNeighborsClassifier model\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print('KNeighborsClassifier Accuracy:', accuracy_knn)\n",
        "print('KNeighborsClassifier Classification Report:')\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "print('KNeighborsClassifier Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-my4Zcu0wYd-"
      },
      "outputs": [],
      "source": [
        "knn_conf_mat = confusion_matrix(y_test, y_pred_knn)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(knn_conf_mat, annot=True, cmap='Reds')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('KNeighborsClassifier Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbqiMzrF4Hh0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision = precision_score(y_test, y_pred_knn)\n",
        "recall = recall_score(y_test, y_pred_knn)\n",
        "f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "plt.bar(['Precision', 'Recall', 'F1 Score'], [precision, recall, f1])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('KNeighborsClassifier Performance Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx86MTgB4cCO"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Create a Random Forest Classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the Random Forest Classifier model\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest Classifier model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print('Random Forest Classifier Accuracy:', accuracy_rf)\n",
        "print('Random Forest Classifier Classification Report:')\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print('Random Forest Classifier Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejLp7CdQ4pXK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision = precision_score(y_test, y_pred_rf)\n",
        "recall = recall_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "plt.bar(['Precision', 'Recall', 'F1 Score'], [precision, recall, f1])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Random Forest Classifier Performance Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjSHJb7W5Day"
      },
      "outputs": [],
      "source": [
        "# Define the accuracy scores\n",
        "accuracy_lr = 0.87\n",
        "accuracy_rf = 0.77\n",
        "accuracy_knn = 0.81\n",
        "\n",
        "# Define the F1 scores\n",
        "f1_lr = 0.89\n",
        "f1_rf = 0.85\n",
        "f1_knn = 0.88\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot the accuracy scores\n",
        "ax[0].bar(['LR', 'Random Forest Classifier', 'KNN Classifier'], [accuracy_lr, accuracy_rf, accuracy_knn])\n",
        "ax[0].set_xlabel('Model')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Model Comparison - Accuracy')\n",
        "\n",
        "# Plot the F1 scores\n",
        "ax[1].bar(['LR', 'Random Forest Classifier', 'KNN Classifier'], [f1_lr, f1_rf, f1_knn])\n",
        "ax[1].set_xlabel('Model')\n",
        "ax[1].set_ylabel('F1 Score')\n",
        "ax[1].set_title('Model Comparison - F1 Score')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWPUBv4WMNot"
      },
      "outputs": [],
      "source": [
        "# Implement the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "print(\"SVM Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svm)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svm)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoiCncbuM9Un"
      },
      "outputs": [],
      "source": [
        "svm_conf_mat = confusion_matrix(y_test, y_pred_svm)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(svm_conf_mat, annot=True, cmap='Reds')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('SVM model Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t04ZBfRuNeFN"
      },
      "outputs": [],
      "source": [
        "precision = precision_score(y_test, y_pred_svm)\n",
        "recall = recall_score(y_test, y_pred_svm)\n",
        "f1 = f1_score(y_test, y_pred_svm)\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "plt.bar(['accuracy', 'Precision', 'Recall', 'F1 Score'], [accuracy, precision, recall, f1])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('SVM Models Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egMh5UZiNvDK"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Create a Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Naive Bayes model\n",
        "print(\"Naive Bayes Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_nb)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_nb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQNuRQHIO3d_"
      },
      "outputs": [],
      "source": [
        "nb_conf_mat = confusion_matrix(y_test, y_pred_nb)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(nb_conf_mat, annot=True, cmap='Greens')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Naive Bayes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6mw6gJIPIbd"
      },
      "outputs": [],
      "source": [
        "precision = precision_score(y_test, y_pred_nb)\n",
        "recall = recall_score(y_test, y_pred_nb)\n",
        "f1 = f1_score(y_test, y_pred_nb)\n",
        "\n",
        "plt.bar(['Precision', 'Recall', 'F1 Score'], [precision, recall, f1])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Naive Bayes Models Metrics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T53qb0HwPUce"
      },
      "outputs": [],
      "source": [
        "# Define the accuracy scores\n",
        "accuracy_svm = 0.88\n",
        "accuracy_nb = 0.81\n",
        "# Define the F1 scores\n",
        "f1_svm = 0.92\n",
        "f1_nb = 0.88\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot the accuracy scores\n",
        "ax[0].bar(['SVM', 'Naive Bayes'], [accuracy_svm, accuracy_nb])\n",
        "ax[0].set_xlabel('Model')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Model Comparison - Accuracy')\n",
        "\n",
        "# Plot the F1 scores\n",
        "ax[1].bar(['SVM', 'Naive Bayes'], [f1_svm, f1_nb])\n",
        "ax[1].set_xlabel('Model')\n",
        "ax[1].set_ylabel('F1 Score')\n",
        "ax[1].set_title('Model Comparison - F1 Score')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lyg12-cpVvjG"
      },
      "outputs": [],
      "source": [
        "# Define the accuracy scores\n",
        "accuracy_lr = 0.87\n",
        "accuracy_rf = 0.77\n",
        "accuracy_knn = 0.81\n",
        "accuracy_svm = 0.88\n",
        "accuracy_nb = 0.81\n",
        "\n",
        "# Define the F1 scores\n",
        "f1_lr = 0.89\n",
        "f1_rf = 0.85\n",
        "f1_knn = 0.88\n",
        "f1_svm = 0.92\n",
        "f1_nb = 0.88\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot the accuracy scores\n",
        "ax[0].bar(['LR', 'Random Forest', 'KNN Classifier', 'SVM', 'Naive Bayes'], [accuracy_lr, accuracy_rf, accuracy_knn, accuracy_svm, accuracy_nb])\n",
        "ax[0].set_xlabel('Model')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Model Comparison - Accuracy')\n",
        "\n",
        "# Plot the F1 scores\n",
        "ax[1].bar(['LR', 'Random Forest', 'KNN Classifier', 'SVM', 'Naive Bayes'], [f1_lr, f1_rf, f1_knn, f1_svm, f1_nb])\n",
        "ax[1].set_xlabel('Model')\n",
        "ax[1].set_ylabel('F1 Score')\n",
        "ax[1].set_title('Model Comparison - F1 Score')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-hrBWNb8aWC"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=5,  # Limit the depth of the tree\n",
        "    min_samples_leaf=10,  # Each leaf must have at least 10 samples\n",
        "    ccp_alpha=0.01  # Use cost complexityÂ pruning\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "# Step 7: Predict on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 8: Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "#\n",
        "\n",
        "# Step 9: Visualize the Decision Tree\n",
        "plt.figure(figsize=(20,10))\n",
        "tree.plot_tree(clf, feature_names=X.columns, class_names=['Not Placed', 'Placed'], filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_stmADf8ElyE"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy_lr = 0.87\n",
        "accuracy_rf = 0.77\n",
        "accuracy_knn = 0.81\n",
        "accuracy_svm = 0.88\n",
        "accuracy_nb = 0.81\n",
        "accuracy_dt = 0.84\n",
        "\n",
        "\n",
        "f1_lr = 0.89\n",
        "f1_rf = 0.85\n",
        "f1_knn = 0.88\n",
        "f1_svm = 0.92\n",
        "f1_nb = 0.88\n",
        "f1_dt = 0.89\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "\n",
        "ax[0].bar(['LR', 'Random Forest', 'KNN Classifier', 'SVM', 'Naive Bayes', 'Decision Tree'],\n",
        "          [accuracy_lr, accuracy_rf, accuracy_knn, accuracy_svm, accuracy_nb, accuracy_dt])\n",
        "ax[0].set_xlabel('Model')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Model Comparison - Accuracy')\n",
        "\n",
        "\n",
        "ax[1].bar(['LR', 'Random Forest', 'KNN Classifier', 'SVM', 'Naive Bayes', 'Decision Tree'],\n",
        "          [f1_lr, f1_rf, f1_knn, f1_svm, f1_nb, f1_dt])\n",
        "ax[1].set_xlabel('Model')\n",
        "ax[1].set_ylabel('F1 Score')\n",
        "ax[1].set_title('Model Comparison - F1 Score')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2, 3, 4]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "y_pred_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned SVM model\n",
        "print(\"Tuned SVM Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svm)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svm)}\")\n"
      ],
      "metadata": {
        "id": "dyjWtTqQjBXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2, 3, 4]  # Relevant for 'poly' kernel\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Display relevant columns for easier interpretation\n",
        "results_df = results_df[['param_C', 'param_kernel', 'param_gamma', 'param_degree', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
        "\n",
        "# Sort by the best score\n",
        "results_df = results_df.sort_values(by='mean_test_score', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Grid Search Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "y_pred_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned SVM model\n",
        "print(\"Tuned SVM Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svm)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svm)}\")\n"
      ],
      "metadata": {
        "id": "gW7JtbYqjB-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the accuracy scores\n",
        "accuracy_lr = 0.87\n",
        "accuracy_knn = 0.81\n",
        "\n",
        "# Define the F1 scores\n",
        "f1_lr = 0.83\n",
        "f1_knn = 0.80\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot the accuracy scores\n",
        "ax[0].bar(['LR', 'KNN Classifier'], [accuracy_lr,  accuracy_knn])\n",
        "ax[0].set_xlabel('Model')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Model Comparison - Accuracy')\n",
        "\n",
        "# Plot the F1 scores\n",
        "ax[1].bar(['LR', 'KNN Classifier'], [f1_lr, f1_knn])\n",
        "ax[1].set_xlabel('Model')\n",
        "ax[1].set_ylabel('F1 Score')\n",
        "ax[1].set_title('Model Comparison - F1 Score')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DU7mopZvkdWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKbKs_oYfnVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data for accuracy and F1 score\n",
        "data = {\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Support Vector Machine\", \"Naive Bayes\",\n",
        "              \"Decision Tree\", \"K-Nearest Neighbours\"],\n",
        "    \"Accuracy\": [0.87, 0.77, 0.88, 0.81, 0.84, 0.81],\n",
        "    \"F1 Score\": [0.89, 0.85, 0.89, 0.88, 0.89, 0.88]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Y8iBFP--jXvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Step 1: Feature Scaling (same as before)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Gradient Boosting Hyperparameter Grid\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Step 3: GridSearchCV with StratifiedKFold\n",
        "grid_search_gb = GridSearchCV(\n",
        "    GradientBoostingClassifier(), param_grid_gb, cv=StratifiedKFold(n_splits=5),\n",
        "    scoring='accuracy', verbose=1, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Step 4: Fit the model\n",
        "grid_search_gb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best hyperparameters and score\n",
        "print(\"Best Parameters (Gradient Boosting):\", grid_search_gb.best_params_)\n",
        "print(\"Best Cross-Validation Score (Gradient Boosting):\", grid_search_gb.best_score_)\n",
        "\n",
        "# Step 5: Evaluate the best Gradient Boosting model on the test set\n",
        "best_gb_model = grid_search_gb.best_estimator_\n",
        "y_pred_gb = best_gb_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Tuned Gradient Boosting Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_gb)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_gb)}\")\n"
      ],
      "metadata": {
        "id": "8BzB7XPrZIO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2, 3, 4]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "y_pred_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned SVM model\n",
        "print(\"Tuned SVM Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svm)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svm)}\")\n"
      ],
      "metadata": {
        "id": "-eKUJ6wrcRRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}